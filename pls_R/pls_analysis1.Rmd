---
title: "NLCD_PLS1"
author: "Cody Flagg"
date: "June 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
library(pls)
library(plyr)
library(caret)

## environment options
knitr::opts_chunk$set(echo = TRUE)
options(digits=4)

inpath <- "~/GitHub/NLCD_rectification/"

filelist <- list.files(inpath, full.names = TRUE)

training_files <- filelist[grepl(pattern = "_training.csv", x = filelist)]

#### combine league stats
multipleCombine <- function(input, ply = llply, sep = ","){
  ply(input, function(x){
    ## append week from file name
    t <- read.csv(x, header=TRUE, sep=sep,stringsAsFactors = FALSE) # read the csv
    t1 <- plyr::rbind.fill(t) # rbind it to a temporary variable
    return(t1) # return the full variable
  }
  )
}

## combine files
inputdata <- multipleCombine(training_files, ply = ldply)

#### >> THIS SUBSET IS USED FOR THE SUBSEQUENT CODE CHUNKS << ####
## filter to three classes of interest ##
subdata <- dplyr::filter(inputdata, NLCD %in% c("SS", "EF", "DF"))
#subdata <- dplyr::filter(inputdata)
```


```{r}
## plot raw data
wavelengths<-seq(1, 426,by=1) # wavelengths captured by machine
reflectance <- subdata[,c(11:ncol(subdata))] # reflectance values 

# need to setup the x-axis, the wavelengths, and a transpose of the reflectance matrix with t()
reflectance.plot = matplot(x = wavelengths, y = t(reflectance),lty=1,xlab="wavelengths(nm)",ylab="Reflectance",type="l", main = "Reflectance by Sample")
```


```{r}
## convert reflectance to a matrix, as this is what plsr() requires
refl = as.matrix(reflectance)
subdata$NLCD <- as.factor(subdata$NLCD)

## convert NLCD character to factor first, then convert the factor to a numeric value so plsr() can analyze data
NLCD_num <- as.matrix(as.numeric(as.factor(subdata$NLCD)),ncol=1) # make numeric matrix

## run the model
m1 <- plsr(NLCD_num ~ log(refl+1), ncomp = 100, validation = "CV")

## these are the numeric classes converted back to NLCD labels
NLCD_back <-factor(NLCD_num, labels = levels(subdata$NLCD), levels = 1:3)

## add predictions from the plsr() model
subdata$pred_num_class <- predict(m1, ncomp = 25) # the output of this is an array, each column in the array is the predicted output for each principal component
#subdata$pred_fac_class <- round(subdata$pred_num_class)

## 1. take the mean prediction from the components (specified by 'ncomp') by applying mean() across a row
## 2. then round that mean, it represents a "vote" for the class value from each component
confusion <- data.frame(actual = NLCD_num, predicted = round(apply(X = subdata$pred_num_class, 1, FUN = mean)))

# cross reference the actual class versus the predicted class
crossRef <- table(confusion)
```


```{r}
barplot(explvar(m1), axis.lty = 1, las = 2, main = "% Variance Explained by Component")

plot(RMSEP(m1), legendpos = "topright", main = "Validation Error")
```

### Loadings for 25 Components - untransformed Y and X

```{r error=FALSE}
loadingplot(m1, comps = 1:25, legendpos = -1, labels = c(1:426), xlab = "Band")
```

### Confusion Matrix -- Full Data Set (not split between training and test sets)

```{r}
# calculate accuracy for each class
## subset the crossRef table because it has classes predicted as 0 and 4 <for 3 class>
if (ncol(crossRef != length(unique(NLCD_num)))){
    caret::confusionMatrix(crossRef[,c(2:4)])
} else {
    caret::confusionMatrix(crossRef)
}

```